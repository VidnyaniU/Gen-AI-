{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall -qqy jupyterlab  # Remove unused packages from Kaggle's base image that conflict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U -q \"google-genai==1.7.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "from IPython.display import HTML, Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting google.api_core\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 KB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5\n",
      "  Downloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.2/316.2 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-auth<3.0.0,>=2.14.1 in /home/hp/.local/lib/python3.10/site-packages (from google.api_core) (2.38.0)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.69.2-py3-none-any.whl (293 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.2/293.2 KB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting proto-plus<2.0.0,>=1.22.3\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 KB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.18.0 in /home/hp/.local/lib/python3.10/site-packages (from google.api_core) (2.32.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/hp/.local/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google.api_core) (0.4.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/hp/.local/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google.api_core) (5.5.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/hp/.local/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google.api_core) (4.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hp/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google.api_core) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.18.0->google.api_core) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.18.0->google.api_core) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.18.0->google.api_core) (1.26.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/hp/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google.api_core) (0.6.1)\n",
      "Installing collected packages: protobuf, proto-plus, googleapis-common-protos, google.api_core\n",
      "Successfully installed google.api_core-2.24.2 googleapis-common-protos-1.69.2 proto-plus-1.26.1 protobuf-6.30.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google.api_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "\n",
    "\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "genai.models.Models.generate_content = retry.Retry(\n",
    "    predicate=is_retriable)(genai.models.Models.generate_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement kaggle_secrets (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for kaggle_secrets\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install kaggle_secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "GOOGLE_API_KEY = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, imagine you have a really, really smart puppy. But this puppy doesn't know anything to start with!\n",
      "\n",
      "That's kinda like AI! AI stands for Artificial Intelligence, which means \"making computers think like people.\"\n",
      "\n",
      "So, how do you teach your puppy tricks? You show it lots of examples, right? You say \"Sit!\" and push its bottom down a little, and give it a treat! If it does it right, you praise it! If it doesn't, you try again.\n",
      "\n",
      "AI is similar. We show the computer lots and lots of examples and tell it what the \"right\" answer is.\n",
      "\n",
      "*   **Like recognizing pictures:** You can show the computer millions of pictures of cats and tell it, \"This is a cat.\" After seeing enough cats, the computer can start to recognize new pictures of cats, even if it's never seen that specific cat before!\n",
      "*   **Like playing games:** You can let a computer play a game like chess over and over. Each time it plays, it learns what moves work and what moves don't. Eventually, it gets so good it can beat even the best human chess players!\n",
      "\n",
      "So, AI is like teaching a computer to learn and solve problems, just like training a super-smart puppy! But instead of treats, we use lots of examples and tell the computer when it's doing things right.\n",
      "\n",
      "Does that make sense?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=\"Explain AI to me like I'm a kid.\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, imagine you have a really, really smart puppy. But this puppy doesn't know anything to start with!\n",
       "\n",
       "That's kinda like AI! AI stands for Artificial Intelligence, which means \"making computers think like people.\"\n",
       "\n",
       "So, how do you teach your puppy tricks? You show it lots of examples, right? You say \"Sit!\" and push its bottom down a little, and give it a treat! If it does it right, you praise it! If it doesn't, you try again.\n",
       "\n",
       "AI is similar. We show the computer lots and lots of examples and tell it what the \"right\" answer is.\n",
       "\n",
       "*   **Like recognizing pictures:** You can show the computer millions of pictures of cats and tell it, \"This is a cat.\" After seeing enough cats, the computer can start to recognize new pictures of cats, even if it's never seen that specific cat before!\n",
       "*   **Like playing games:** You can let a computer play a game like chess over and over. Each time it plays, it learns what moves work and what moves don't. Eventually, it gets so good it can beat even the best human chess players!\n",
       "\n",
       "So, AI is like teaching a computer to learn and solve problems, just like training a super-smart puppy! But instead of treats, we use lots of examples and tell the computer when it's doing things right.\n",
       "\n",
       "Does that make sense?\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Zlork! It's nice to meet you. How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat = client.chats.create(model='gemini-2.0-flash', history=[])\n",
    "response = chat.send_message('Hello! My name is Zlork.')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's an interesting fact about dinosaurs:\n",
      "\n",
      "**Some dinosaurs had feathers!**\n",
      "\n",
      "While we often picture dinosaurs as scaly reptiles, increasing fossil evidence shows that many, especially theropods (the group that includes Tyrannosaurus Rex and Velociraptor), had feathers. These feathers weren't always used for flight; they could have been used for:\n",
      "\n",
      "*   **Insulation:** Keeping them warm.\n",
      "*   **Display:** Attracting mates or intimidating rivals.\n",
      "*   **Camouflage:** Blending in with their environment.\n",
      "\n",
      "So, the image of a completely scaly dinosaur is becoming more and more outdated. Think fluffy raptors! Pretty cool, right?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message('Can you tell me something interesting about dinosaurs?')\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I remember your name is Zlork.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message('Do you remember what my name is?')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n"
     ]
    }
   ],
   "source": [
    "for model in client.models.list():\n",
    "  print(model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OUTPUT LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## The Humble Olive: A Cornerstone of Modern Society\n",
      "\n",
      "The olive, a seemingly simple fruit borne from the resilient Olea europaea tree, has woven its way into the fabric of human civilization for millennia. From its origins in the Mediterranean basin to its current global presence, the olive and its oil have permeated various aspects of our lives, playing a vital role in culinary traditions, health and wellness, economic landscapes, and even artistic expression. While often overlooked in the face of more exotic or flashier ingredients, the humble olive deserves recognition for its profound and enduring importance in modern society.\n",
      "\n",
      "Perhaps the most immediately recognizable significance of the olive lies in its culinary contribution. Olive oil, a cornerstone of Mediterranean cuisine and increasingly embraced worldwide, boasts a unique flavor profile ranging from delicate and fruity to bold and peppery. Its versatility is undeniable; it serves as a foundational element in salads, dips, and sauces, enhances the flavors of grilled meats and vegetables, and acts as a finishing touch to elevate simple dishes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.genai import types\n",
    "\n",
    "short_config = types.GenerateContentConfig(max_output_tokens=200)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=short_config,\n",
    "    contents='Write a 1000 word essay on the importance of olives in modern society.')\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TEMPERATURE\n",
    "Temperature controls the degree of randomness in token selection. Higher temperatures result in a higher number of candidate tokens from which the next output token is selected, and can produce more diverse results, while lower temperatures have the opposite effect, such that a temperature of 0 results in greedy decoding, selecting the most probable token at each step.\n",
    "\n",
    "Temperature doesn't provide any guarantees of randomness, but it can be used to \"nudge\" the output somewhat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure.\n",
      " -------------------------\n",
      "Purple\n",
      " -------------------------\n",
      "Turquoise\n",
      " -------------------------\n",
      "Cerulean.\n",
      " -------------------------\n",
      "Orange\n",
      " -------------------------\n"
     ]
    }
   ],
   "source": [
    "high_temp_config = types.GenerateContentConfig(temperature=2.0)\n",
    "\n",
    "\n",
    "for _ in range(5):\n",
    "  response = client.models.generate_content(\n",
    "      model='gemini-2.0-flash',\n",
    "      config=high_temp_config,\n",
    "      contents='Pick a random colour... (respond in a single word)')\n",
    "\n",
    "  if response.text:\n",
    "    print(response.text, '-' * 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOP P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-P defines the probability threshold that, once cumulatively exceeded, tokens stop being selected as candidates. A top-P of 0 is typically equivalent to greedy decoding, and a top-P of 1 typically selects every token in the model's vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jasper wasn't your average tabby. Sure, he enjoyed naps in sunbeams and batting at dust bunnies, but a yearning for something more thrummed beneath his striped fur. He dreamt of whispering winds, rustling leaves, and smells that weren't just tuna and lavender laundry detergent. So, one crisp autumn morning, Jasper decided to leave the safety of his window seat and embark on an adventure.\n",
      "\n",
      "He slipped through the slightly ajar back door, a thrill tingling his whiskers. The backyard, usually just a blurry green expanse, was now a jungle of towering sunflowers gone to seed. He stalked through them, a tiny tiger in a golden forest, the crunch of fallen leaves a symphony beneath his paws.\n",
      "\n",
      "His journey led him to the edge of the woods. He hesitated, the scent of damp earth and unknown creatures filling his senses. Fear nipped at him, but curiosity won. He plunged into the shadows.\n",
      "\n",
      "The woods were a kaleidoscope of colors. Scarlet leaves danced on the breeze, amber sunlight filtered through the canopy, and the air buzzed with the activity of squirrels and unseen birds. He chased butterflies with wings like stained glass, dodged grumpy beetles lumbering across fallen logs, and even had a brief, tense standoff with a robin who clearly considered him an unwelcome guest.\n",
      "\n",
      "He followed a babbling brook, mesmerized by the way the sunlight glittered on the water. He lapped at it cautiously, the water cool and refreshing. As he drank, he heard a faint whimper.\n",
      "\n",
      "Following the sound, he found a small, shivering creature huddled beneath a fern – a baby rabbit, its fur matted and its eyes wide with fear. Jasper, who normally wouldn't hesitate to chase a rabbit, felt a surge of unexpected compassion. He nudged the rabbit with his nose, purring softly.\n",
      "\n",
      "The rabbit, tentatively, nuzzled back. Jasper stayed with the rabbit, purring and keeping it warm, until its mother, a large, watchful hare, hopped out from the bushes. The hare glared at Jasper for a moment, then, surprisingly, nudged him with her nose in a silent thank you before gathering her baby and hopping away.\n",
      "\n",
      "Jasper watched them go, a strange warmth blossoming in his chest. He had protected a creature, not hunted it. He had been brave, not just curious.\n",
      "\n",
      "As dusk began to settle, painting the sky in hues of orange and purple, a wave of homesickness washed over him. He was tired, his paws aching, and the comforting scent of tuna suddenly seemed overwhelmingly appealing.\n",
      "\n",
      "He retraced his steps, guided by the fading light and the faint scent of his home. When he reached the back door, it was still ajar. He slipped back inside, unnoticed, and curled up on his favorite window seat.\n",
      "\n",
      "The adventure had changed him. He was still Jasper, the tabby cat who loved naps and dust bunnies, but now he was also Jasper, the adventurer, the protector, the friend of a rabbit. He closed his eyes, the memories of whispering leaves and glittering water swirling in his dreams. He knew, with absolute certainty, that this wouldn't be his last adventure. The world outside was too fascinating, too full of wonder, to ignore. And Jasper, after all, was not your average tabby.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = types.GenerateContentConfig(\n",
    "    temperature=1.0,\n",
    "    top_p=0.95,\n",
    ")\n",
    "\n",
    "story_prompt = \"You are a creative writer. Write a short story about a cat who goes on an adventure.\"\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=model_config,\n",
    "    contents=story_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot\n",
    "Zero-shot prompts are prompts that describe the request for the model directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = types.GenerateContentConfig(\n",
    "    temperature=0.1,\n",
    "    top_p=1,\n",
    "    max_output_tokens=5,\n",
    ")\n",
    "\n",
    "zero_shot_prompt = \"\"\"Classify movie reviews as POSITIVE, NEUTRAL or NEGATIVE.\n",
    "Review: \"Her\" is a disturbing study revealing the direction\n",
    "humanity is headed if AI is allowed to keep evolving,\n",
    "unchecked. I wish there were more movies like this masterpiece.\n",
    "Sentiment: \"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=model_config,\n",
    "    contents=zero_shot_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "\n",
    "class Sentiment(enum.Enum):\n",
    "    POSITIVE = \"positive\"\n",
    "    NEUTRAL = \"neutral\"\n",
    "    NEGATIVE = \"negative\"\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=types.GenerateContentConfig(\n",
    "        response_mime_type=\"text/x.enum\",\n",
    "        response_schema=Sentiment\n",
    "    ),\n",
    "    contents=zero_shot_prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum_response = response.parsed\n",
    "print(enum_response)\n",
    "print(type(enum_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = \"\"\"Parse a customer's pizza order into valid JSON:\n",
    "\n",
    "EXAMPLE:\n",
    "I want a small pizza with cheese, tomato sauce, and pepperoni.\n",
    "JSON Response:\n",
    "```\n",
    "{\n",
    "\"size\": \"small\",\n",
    "\"type\": \"normal\",\n",
    "\"ingredients\": [\"cheese\", \"tomato sauce\", \"pepperoni\"]\n",
    "}\n",
    "```\n",
    "\n",
    "EXAMPLE:\n",
    "Can I get a large pizza with tomato sauce, basil and mozzarella\n",
    "JSON Response:\n",
    "```\n",
    "{\n",
    "\"size\": \"large\",\n",
    "\"type\": \"normal\",\n",
    "\"ingredients\": [\"tomato sauce\", \"basil\", \"mozzarella\"]\n",
    "}\n",
    "```\n",
    "\n",
    "ORDER:\n",
    "\"\"\"\n",
    "\n",
    "customer_order = \"Give me a large with cheese & pineapple\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0.1,\n",
    "        top_p=1,\n",
    "        max_output_tokens=250,\n",
    "    ),\n",
    "    contents=[few_shot_prompt, customer_order])\n",
    "\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
